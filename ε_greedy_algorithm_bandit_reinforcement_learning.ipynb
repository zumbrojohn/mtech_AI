{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TczG_JfndcoZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class MultiArmedBandit:\n",
        "    def __init__(self, k=10, stationary=True, alpha=None, c=2, gradient=False, baseline=True):\n",
        "        self.k = k  # Number of arms\n",
        "        self.stationary = stationary  # Whether rewards change over time\n",
        "        self.alpha = alpha  # Step size for nonstationary problems\n",
        "        self.c = c  # UCB exploration parameter\n",
        "        self.gradient = gradient  # Use gradient bandit method\n",
        "        self.baseline = baseline  # Use baseline for gradient method\n",
        "\n",
        "        # True action values (stationary or nonstationary)\n",
        "        self.q_true = np.random.normal(0, 1, self.k)\n",
        "        self.q_est = np.zeros(self.k)  # Estimated values\n",
        "        self.action_count = np.zeros(self.k)  # Action selection count\n",
        "        self.time = 0  # Time step\n",
        "        self.average_reward = 0  # Baseline for gradient bandit\n",
        "        self.preferences = np.zeros(self.k)  # Preferences for gradient method\n",
        "\n",
        "    def select_action(self, method=\"epsilon-greedy\", epsilon=0.1):\n",
        "        if method == \"epsilon-greedy\":\n",
        "            if np.random.rand() < epsilon:\n",
        "                return np.random.choice(self.k)  # Exploration\n",
        "            return np.argmax(self.q_est)  # Exploitation\n",
        "\n",
        "        elif method == \"optimistic\":\n",
        "            return np.argmax(self.q_est)  # Always pick best-known option\n",
        "\n",
        "        elif method == \"ucb\":\n",
        "            if np.any(self.action_count == 0):\n",
        "                return np.argmin(self.action_count)  # Pick an untried action first\n",
        "            ucb_values = self.q_est + self.c * np.sqrt(np.log(self.time + 1) / (self.action_count + 1e-5))\n",
        "            return np.argmax(ucb_values)\n",
        "\n",
        "        elif method == \"gradient\":\n",
        "            exp_prefs = np.exp(self.preferences)\n",
        "            probabilities = exp_prefs / np.sum(exp_prefs)\n",
        "            return np.random.choice(self.k, p=probabilities)\n",
        "\n",
        "    def update_estimate(self, action, reward, method=\"epsilon-greedy\"):\n",
        "        self.time += 1\n",
        "        self.action_count[action] += 1\n",
        "\n",
        "        if method == \"gradient\":\n",
        "            probabilities = np.exp(self.preferences) / np.sum(np.exp(self.preferences))\n",
        "            if self.baseline:\n",
        "                self.average_reward += (reward - self.average_reward) / self.time\n",
        "            self.preferences[action] += self.alpha * (reward - self.average_reward) * (1 - probabilities[action])\n",
        "            self.preferences -= self.alpha * (reward - self.average_reward) * probabilities\n",
        "\n",
        "        else:\n",
        "            step_size = 1 / self.action_count[action] if self.alpha is None else self.alpha\n",
        "            self.q_est[action] += step_size * (reward - self.q_est[action])\n",
        "\n",
        "        if not self.stationary:\n",
        "            self.q_true += np.random.normal(0, 0.01, self.k)  # Small random drift in true values"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    bandit = MultiArmedBandit(k=10, stationary=False, alpha=0.1, c=2, gradient=True, baseline=True)\n",
        "\n",
        "    rewards = []\n",
        "    for _ in range(1000):  # Run for 1000 steps\n",
        "        action = bandit.select_action(method=\"epsilon-greedy\", epsilon=0.1)\n",
        "        reward = np.random.normal(bandit.q_true[action], 1)  # Sample reward\n",
        "        bandit.update_estimate(action, reward, method=\"epsilon-greedy\")\n",
        "        rewards.append(reward)\n",
        "\n",
        "    print(\"Final Estimated Values of Arms:\", bandit.q_est)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yVB8UT6dp1-",
        "outputId": "fc631907-f26c-4ad3-ad4a-f6f5d552bd49"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Estimated Values of Arms: [ 1.66387785  0.65580474 -0.47443214  0.20600693 -0.443106   -0.46891081\n",
            "  0.17439698  0.37757008 -0.34369471 -0.46814821]\n"
          ]
        }
      ]
    }
  ]
}